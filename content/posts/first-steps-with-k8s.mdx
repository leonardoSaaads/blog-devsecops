---
title: "Aprendendo K8s"
date: "2025-10-31"
tags: ["KUBERNETS", "DEVSECOPS", "DEVOPS"]
description: "Os primeiros passos com Kubernets"
---

# Os primeiros passos com Kubernets

Essa publica√ß√£o ser√° muito mais sobre anota√ß√µes minhas no aprendizado de kubernets do que um tutorial de aprendizado. Para que que a gente consiga prosseguir 
nesse t√≥pico, ser√° necess√°rio definirmos alguns conceitos/estruturas antes. Vamos come√ßar primeiro explicando o b√°sico e aos poucos vamos avan√ßando:

- **Pod**: apartamento (containers moram nele)
- **Node**: pr√©dio (Pods ficam nele) [Geralmente um servidor ou PC]
- **Cluster**: condom√≠nio (Nodes ficam nele) [Coordena uma s√©rie de servidores e m√°quinas]
- **Deployment**: s√≠ndico (garante tudo funcionando) [Gerencia v√°rios Pods]
- **Service**: portaria (recebe visitas e encaminha) [Encaminha com load balancing]
- **Ingress**: guarita da rua (primeira entrada) [Encaminha para o Service]
- **Namespace**: blocos separados no condom√≠nio [Um bloco virtual de encapsulamento]

Umas das primeiras coisas que voc√™ PRECISA entender √© que existe uma hierarquia entre os processos. Essa hierarquia √© definida da seguinte forma: **Container ‚Üí Pod ‚Üí Node ‚Üí Cluster** 

- **Container** fica DENTRO do **Pod**
- **Pod** fica DENTRO do **Node**  
- **Node** fica DENTRO do **Cluster**
- Um **Pod** pode ter m√∫ltiplos **Containers** (Containers no mesmo Pod devem ser insepar√°veis - um depende do outro)

Verifique na imagem abaixo:

<p align="center">
  <img src="/images/k8s/pod.png" />
</p>

Por padr√£o, o **Pod** √© ef√™mero, ou seja, se um **pod** morrer, o seu ciclo de vida se encerra e nada mais √© feito. Devido a esse motivo √© utilizado o 
**Deployment**, pois ele gerencia v√°rios **Pods**. O **Deployment** define quantas r√©plicas quer (ex: 3 **pods**), se um **Pod** morrer, ele cria outro automaticamente e 
sempre mant√©m o n√∫mero desejado de r√©plicas;

O problema do sistema **Pod/Deployment** √© que os **Pods** possuem IPs tempor√°rios, ou seja, se um **Pod** morrer, o **Deployment** cria outro, mas o IP utilizado √© 
trocado, ficando dificil o seu gerenciamento. Nesse sentido, o **Service** surgiu da necessidade de um ponto de acesso fixo. O **Service** tem um IP fixo
e faz o load balancing entre os **Pods**;

Por fim, h√° um elemento que precisa ser destacado: **Ingress**. Esse elemento est√° muito relacionado com a internet. Quando um usu√°rio 
acessa dom√≠nio (nginx.exemplo.com), o **Ingress** recebe e roteia para **Service** correto, o **Service** roteia para o **Pod** e o 
**Pod** processa e responde (resposta retorna via mesmo caminho roteado);

Quero destacar tamb√©m que h√° um ciclo de vida bem defindo para os **Pods** que envolve alguns detalhes como *Restart Policy*. 
Contudo, para n√£o deixar o conte√∫do extremamente grande, veja a imagem resumida abaixo que trata deste tema;

<p align="center">
  <img src="/images/k8s/pod_life_cicle.png" />
</p>

Vamos agora da in√≠cio a uma s√©rie de "n√≠veis", contudo fique atento aos pr√©-requisitos abaixo:

## Pr√©-requisitos

Para seguir este tutorial voc√™ precisa:
- Cluster Kubernetes rodando (k3s, minikube, ou cloud);
- kubectl instalado e configurado;
- Acesso via SSH ao servidor (se aplic√°vel);
- Conhecimento b√°sico de terminal Linux;

Neste "Tutorial", usei o K3s de um servidor local - acesso via SSH e utilizei o VSCode para port forwading para o meu pc pessoal. Voc√™ 
pode (e deve) escolher o setup que melhor desejar.

## N√≠vel 1: Seu Primeiro Pod

Vamos criar apenas um arquivo para executar um container nginx no Kubernetes.

**Estrutura:**
```bash
projeto-k8s/
‚îî‚îÄ‚îÄ pod.yaml
```

**Arquivo: pod.yaml**
```yaml
# apiVersion: Define qual vers√£o da API do Kubernetes usar
# v1 = API core/est√°vel do Kubernetes (para recursos b√°sicos como Pod, Service)
# Outras vers√µes: apps/v1 (Deployment), networking.k8s.io/v1 (Ingress)
# SEMPRE obrigat√≥rio. Define "qual dicion√°rio" o K8s vai usar para entender este arquivo
apiVersion: v1

# kind: Tipo de recurso que voc√™ est√° criando
# Op√ß√µes comuns: Pod, Service, Deployment, ConfigMap, Secret, etc
# SEMPRE obrigat√≥rio. Diz ao K8s "o que" voc√™ est√° criando
kind: Pod

# metadata: Informa√ß√µes que identificam este recurso
metadata:
  # name: Nome √∫nico deste Pod no namespace
  # Regras: letras min√∫sculas, n√∫meros, h√≠fens (sem espa√ßos ou caracteres especiais)
  # SEMPRE obrigat√≥rio
  name: meu-nginx
  
  # labels: Etiquetas chave-valor para organizar e selecionar recursos
  # N√£o s√£o obrigat√≥rios, mas EXTREMAMENTE importantes
  # Services e Deployments usam labels para encontrar Pods
  labels:
    app: nginx  # Voc√™ pode criar qualquer label: "ambiente: producao", "versao: 1.0"

# spec: Especifica√ß√£o - descreve o estado desejado do recurso
# SEMPRE obrigat√≥rio. √â o "corpo" da configura√ß√£o
spec:
  # containers: Lista de containers que rodar√£o dentro deste Pod
  # Um Pod pode ter m√∫ltiplos containers (uso avan√ßado)
  # SEMPRE obrigat√≥rio (precisa de pelo menos 1 container)
  containers:
  
  # O h√≠fen "-" indica item de uma lista (este √© o container 1)
  - name: nginx  # Nome do container dentro do Pod (obrigat√≥rio)
    
    # image: Imagem Docker a ser usada
    # Formato: [registro/]nome[:tag]
    # nginx:latest = Docker Hub / nginx / vers√£o latest
    # Obrigat√≥rio
    image: nginx:latest
    
    # ports: Lista de portas que o container exp√µe
    # N√ÉO obrigat√≥rio, mas boa pr√°tica para documenta√ß√£o
    # N√£o abre porta externamente, apenas documenta
    ports:
    - containerPort: 80  # Porta que o nginx escuta dentro do container
```

**Comandos para executar no seu servidor:**

```bash
# kubectl = Ferramenta de linha de comando para o Kubernetes
# Sintaxe geral: kubectl [comando] [tipo] [nome] [flags]

# 1. APPLY - Cria ou atualiza recursos
sudo kubectl apply -f pod.yaml
# apply = "aplicar configura√ß√£o"
# -f = --filename (indica que voc√™ est√° passando um arquivo)
# Sem -f, o kubectl n√£o sabe de onde ler a configura√ß√£o
# Alternativa: kubectl create -f pod.yaml (s√≥ cria, n√£o atualiza)

# 2. GET - Lista recursos
sudo kubectl get pods
# get = "obter/listar"
# pods = tipo de recurso (pode ser: services, deployments, nodes, etc)
# Flags √∫teis:
#   -o wide    = mais detalhes (IP, Node)
#   -o yaml    = sa√≠da em formato YAML
#   --watch    = monitora mudan√ßas em tempo real (-w)

# 3. DESCRIBE - Detalhes completos de um recurso
sudo kubectl describe pod meu-nginx
# describe = "descrever detalhadamente"
# pod = tipo
# meu-nginx = nome do recurso
# Mostra: eventos, status, configura√ß√£o, logs de erro

# 4. PORT-FORWARD - T√∫nel tempor√°rio para acessar o Pod
sudo kubectl port-forward pod/meu-nginx 8080:80
# port-forward = "encaminhar porta"
# pod/meu-nginx = tipo/nome
# 8080:80 = porta_local:porta_container
# Permite acessar http://localhost:8080 que vai para a porta 80 do Pod
# Funciona apenas enquanto o comando estiver rodando

# 5. DELETE - Remove recursos
sudo kubectl delete pod meu-nginx
# delete = "deletar"
# Pode tamb√©m: kubectl delete -f pod.yaml (deleta tudo que est√° no arquivo)

# COMANDOS EXTRAS √öTEIS
sudo kubectl logs meu-nginx              # Ver logs do container
sudo kubectl logs meu-nginx -f           # Ver logs em tempo real (-f = follow)
sudo kubectl logs meu-nginx --tail=50    # Ver √∫ltimas 50 linhas
sudo kubectl exec -it meu-nginx -- bash  # Acessar terminal dentro do container (-it = interativo)
sudo kubectl get pods -A                 # Listar pods de todos os namespaces (-A = --all-namespaces)

### Problemas Comuns - N√≠vel 1
# - Pod fica em "ImagePullBackOff": Problema ao baixar imagem. Verifique internet/nome da imagem.
# - Pod fica em "CrashLoopBackOff": Container inicia e morre. Veja logs com `kubectl logs`.
```

**O que acontece:**
- Kubernetes baixa a imagem nginx
- Cria um container dentro de um Pod
- Exp√µe a porta 80 internamente no cluster

**Problema deste n√≠vel:** Se o Pod morrer, voc√™ precisa recri√°-lo manualmente. N√£o h√° redund√¢ncia.

___

## N√≠vel 2: Deployment

**Problema do N√≠vel 1 resolvido:** 
- Pod morre ‚Üí voc√™ precisa recri√°-lo manualmente
- Sem escalabilidade (apenas 1 Pod)
- Sem controle de vers√£o/rollback

**Solu√ß√£o do Deployment:**
- Mant√©m n√∫mero desejado de Pods sempre rodando (r√©plicas)
- Se um Pod morrer, cria automaticamente outro
- Permite atualizar a aplica√ß√£o sem downtime
- Hist√≥rico de vers√µes com rollback

<p align="center">
  <img src="/images/k8s/deployment.png" />
</p>

**Estrutura:**
```bash
projeto-k8s/
‚îú‚îÄ‚îÄ pod.yaml (n√≠vel 1 - pode manter para refer√™ncia)
‚îî‚îÄ‚îÄ deployment.yaml (n√≠vel 2 - novo)
```

**Arquivo: deployment.yaml**
```yaml
# apiVersion: apps/v1 (diferente do Pod que era v1)
# apps/v1 = API para recursos de aplica√ß√£o (Deployment, StatefulSet, DaemonSet)
# Deployment √© um recurso mais avan√ßado que Pod simples
apiVersion: apps/v1

# kind: Tipo de recurso - Deployment
# Deployment gerencia Pods automaticamente
kind: Deployment

# metadata: Informa√ß√µes do Deployment (n√£o dos Pods que ele cria)
metadata:
  # Nome deste Deployment
  name: nginx-deployment
  
  # Labels do pr√≥prio Deployment (opcional, mas boa pr√°tica)
  labels:
    app: nginx

# spec: Especifica√ß√£o do Deployment
spec:
  # replicas: Quantos Pods id√™nticos voc√™ quer rodando
  # K8s garante que sempre haver√° este n√∫mero de Pods ativos
  # Se um Pod morrer, K8s cria outro automaticamente
  # Padr√£o: 1 (se omitido)
  replicas: 3
  
  # selector: Como o Deployment encontra quais Pods gerenciar
  # OBRIGAT√ìRIO e CR√çTICO
  # Deve corresponder aos labels definidos em template.metadata.labels
  selector:
    matchLabels:
      app: nginx  # Procura Pods com label "app: nginx"
  
  # template: Modelo do Pod que ser√° criado
  # √â basicamente um Pod.yaml embutido aqui dentro
  template:
    # metadata do Pod (n√£o do Deployment)
    metadata:
      # Labels que os Pods criados ter√£o
      # DEVE corresponder ao selector.matchLabels acima
      labels:
        app: nginx  # Mesma label do selector
    
    # spec do Pod - igual ao pod.yaml do N√≠vel 1
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        
        ports:
        - containerPort: 80
        
        # resources: Limites de CPU e mem√≥ria (opcional, mas recomendado)
        # Ajuda o K8s a decidir onde alocar o Pod
        resources:
          # requests: M√≠nimo garantido
          requests:
            memory: "64Mi"   # 64 Megabytes
            cpu: "250m"      # 250 milicores (0.25 de um core)
          # limits: M√°ximo permitido
          limits:
            memory: "128Mi"
            cpu: "500m"
```

**Comandos Detalhados:**

```bash
# 1. DELETAR O POD DO N√çVEL 1 (se ainda existir)
sudo kubectl delete pod meu-nginx
# N√£o pode ter conflito de portas/nomes

# 2. CRIAR O DEPLOYMENT
sudo kubectl apply -f deployment.yaml
# apply: cria ou atualiza
# K8s vai criar o Deployment e automaticamente criar 3 Pods

# 3. VERIFICAR O DEPLOYMENT
sudo kubectl get deployments
# Mostra: NAME, READY (Pods prontos/desejados), UP-TO-DATE, AVAILABLE, AGE
# Exemplo de sa√≠da:
# NAME               READY   UP-TO-DATE   AVAILABLE   AGE
# nginx-deployment   3/3     3            3           10s

# 4. VERIFICAR OS PODS CRIADOS PELO DEPLOYMENT
sudo kubectl get pods
# Agora voc√™ ver√° 3 Pods com nomes tipo: nginx-deployment-xxxxxxxxx-xxxxx
# O Deployment adiciona hash aleat√≥rio ao nome
# Status deve ser "Running"

# 5. VER DETALHES DO DEPLOYMENT
sudo kubectl describe deployment nginx-deployment
# Mostra: estrat√©gia de atualiza√ß√£o, eventos, condi√ß√µes, Pods gerenciados

# 6. TESTE DE AUTO-RECUPERA√á√ÉO - Deletar um Pod manualmente
sudo kubectl get pods  # Copie o nome de um dos Pods
sudo kubectl delete pod nginx-deployment-xxxxxxxxx-xxxxx
# Imediatamente ap√≥s deletar:
sudo kubectl get pods --watch
# Voc√™ ver√°: Pod deletado ‚Üí Deployment detecta ‚Üí Cria novo Pod automaticamente
# Pressione Ctrl+C para sair do --watch

# 7. ESCALAR O DEPLOYMENT (mudar n√∫mero de r√©plicas)
sudo kubectl scale deployment nginx-deployment --replicas=5
# Agora ter√° 5 Pods rodando
sudo kubectl get pods  # Confirme os 5 Pods

# Voltar para 3:
sudo kubectl scale deployment nginx-deployment --replicas=3

# 8. ACESSAR UM DOS PODS (t√∫nel tempor√°rio)
sudo kubectl get pods  # Copie nome de qualquer Pod
sudo kubectl port-forward pod/nginx-deployment-xxxxxxxxx-xxxxx 8080:80
# Acesse: http://localhost:8080

# 9. DELETAR TUDO
sudo kubectl delete deployment nginx-deployment
# Deleta o Deployment E todos os Pods que ele gerencia
```

**O que acontece:**
- Deployment cria 3 Pods id√™nticos
- Se voc√™ deletar 1 Pod, Deployment recria automaticamente
- Pode escalar facilmente (aumentar/diminuir r√©plicas)
- Todos os Pods recebem nomes √∫nicos com hash aleat√≥rio

**Problema deste n√≠vel:** 
- Voc√™ acessa os Pods individualmente por nome (inst√°vel)
- Se um Pod for recriado, o nome muda
- N√£o h√° balanceamento de carga entre os 3 Pods
- N√£o h√° endpoint √∫nico para acessar a aplica√ß√£o

___

## N√≠vel 3: Service

**Problema do N√≠vel 2 resolvido:**
- Pods morrem e s√£o recriados com nomes diferentes
- Voc√™ precisa saber o nome espec√≠fico de cada Pod para acess√°-lo
- Sem balanceamento de carga entre as 3 r√©plicas
- Acesso inst√°vel (port-forward √© tempor√°rio e manual)

**Solu√ß√£o do Service:**
- Cria um endpoint est√°vel (IP fixo + DNS) para acessar os Pods
- Balanceamento de carga autom√°tico entre todas as r√©plicas
- Mesmo que Pods sejam recriados, o Service continua funcionando
- Abstrai a complexidade de m√∫ltiplos Pods

<p align="center">
  <img src="/images/k8s/service.png" />
</p>

**Estrutura:**
```bash
projeto-k8s/
‚îú‚îÄ‚îÄ pod.yaml (n√≠vel 1 - refer√™ncia)
‚îú‚îÄ‚îÄ deployment.yaml (n√≠vel 2 - mant√©m rodando)
‚îî‚îÄ‚îÄ service.yaml (n√≠vel 3 - novo)
```

**Arquivo: service.yaml**
```yaml
# apiVersion: v1 (mesma do Pod)
# Service √© um recurso da API core/est√°vel
apiVersion: v1

# kind: Service
# Cria um balanceador de carga interno e endpoint est√°vel
kind: Service

# metadata: Informa√ß√µes do Service
metadata:
  # Nome do Service
  # Este nome vira um DNS interno: nginx-service.default.svc.cluster.local
  # Outros Pods podem acessar via: http://nginx-service
  name: nginx-service
  
  # Labels do pr√≥prio Service (opcional)
  labels:
    app: nginx

# spec: Especifica√ß√£o do Service
spec:
  # type: Tipo de Service - define como ser√° exposto
  # Tipos dispon√≠veis:
  #   ClusterIP (padr√£o): Apenas interno no cluster (n√£o acessa de fora)
  #   NodePort: Exp√µe em uma porta em todos os Nodes (acessa externamente)
  #   LoadBalancer: Cria load balancer externo (cloud providers)
  #   ExternalName: Mapeia para DNS externo (uso avan√ßado)
  type: NodePort
  # Usamos NodePort para voc√™ acessar via IP do servidor SSH
  
  # selector: Como o Service encontra os Pods para rotear tr√°fego
  # CR√çTICO: Deve corresponder aos labels dos Pods no Deployment
  selector:
    app: nginx  # Procura Pods com label "app: nginx"
  
  # ports: Configura√ß√£o de portas
  # Lista das portas que o Service exp√µe
  ports:
    # O h√≠fen "-" indica item de lista (pode ter m√∫ltiplas portas)
    - protocol: TCP  # Protocolo (TCP ou UDP)
      
      # port: Porta que o Service exp√µe internamente no cluster
      # Outros Pods acessam o Service por esta porta
      port: 80
      
      # targetPort: Porta do container dos Pods (containerPort do Deployment)
      # O Service redireciona tr√°fego da "port" para "targetPort" dos Pods
      # Deve corresponder ao containerPort (80) do nginx
      targetPort: 80
      
      # nodePort: Porta exposta em TODOS os Nodes do cluster
      # Somente quando type: NodePort ou LoadBalancer
      # Range: 30000-32767 (padr√£o do K8s)
      # Se omitido, K8s escolhe uma porta aleat√≥ria neste range
      nodePort: 30080
      # Voc√™ acessar√° via: http://IP_DO_SERVIDOR:30080
```

**Comandos Detalhados:**

```bash
# 1. GARANTIR QUE O DEPLOYMENT EST√Å RODANDO
sudo kubectl get deployments
# Se n√£o estiver, crie novamente:
# sudo kubectl apply -f deployment.yaml

# 2. CRIAR O SERVICE
sudo kubectl apply -f service.yaml
# apply: cria ou atualiza o Service
# -f: especifica o arquivo
# K8s cria o Service e conecta aos Pods automaticamente

# 3. VERIFICAR O SERVICE CRIADO
sudo kubectl get services
# Tamb√©m pode usar: sudo kubectl get svc (svc = abrevia√ß√£o de service)
# Colunas importantes:
#   NAME: nome do service
#   TYPE: ClusterIP, NodePort, LoadBalancer
#   CLUSTER-IP: IP interno do cluster
#   EXTERNAL-IP: IP externo (se LoadBalancer)
#   PORT(S): porta_service:nodePort/protocol
#   AGE: tempo desde cria√ß√£o
# Exemplo de sa√≠da:
# NAME            TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
# nginx-service   NodePort   10.43.xxx.xxx   <none>        80:30080/TCP   5s

# 4. VER DETALHES DO SERVICE
sudo kubectl describe service nginx-service
# Mostra:
#   - IP do Service
#   - Endpoints: IPs dos Pods que o Service est√° roteando (balanceamento)
#   - Porta NodePort
#   - Selector usado
# Procure por "Endpoints:" - deve listar os IPs dos 3 Pods

# 5. VERIFICAR ENDPOINTS (Pods conectados ao Service)
sudo kubectl get endpoints nginx-service
# Mostra os IPs reais dos Pods que o Service est√° balanceando
# Deve listar 3 IPs (um para cada r√©plica)
# Tamb√©m pode usar: sudo kubectl get ep nginx-service

# 6. ACESSAR O SERVICE
# Op√ß√£o A: Via NodePort (porta 30080)
# No servidor SSH, descubra o IP:
ip addr show
# Ou use localhost se estiver no pr√≥prio servidor:
curl http://localhost:30080
# Deve retornar o HTML padr√£o do nginx

# Op√ß√£o B: Se tiver acesso SSH com t√∫nel
# Na sua m√°quina local (n√£o no servidor):
# ssh -L 8080:localhost:30080 usuario@IP_DO_SERVIDOR
# Depois acesse: http://localhost:8080

# Op√ß√£o C: Via IP externo do servidor
# Se o firewall permitir, acesse diretamente:
# http://IP_DO_SERVIDOR:30080

# 7. TESTAR BALANCEAMENTO DE CARGA
# Cada requisi√ß√£o vai para um Pod diferente
for i in {1..10}; do
  curl -s http://localhost:30080 | grep -i "welcome"
  echo "Requisi√ß√£o $i"
done
# Todos devem retornar "Welcome to nginx"

# 8. TESTE DE RESILI√äNCIA
# Deletar um Pod e ver que o Service continua funcionando
sudo kubectl get pods  # Copie nome de um Pod
sudo kubectl delete pod nginx-deployment-xxxxxxxxx-xxxxx

# Enquanto o Pod est√° sendo recriado, fa√ßa requisi√ß√µes:
curl http://localhost:30080
# O Service continua respondendo! Redireciona para os outros 2 Pods
# Quando o 3¬∫ Pod estiver pronto, volta ao balanceamento entre 3

# 9. VER LOGS DE REQUISI√á√ïES (opcional)
sudo kubectl logs -l app=nginx --tail=20
# -l app=nginx: seleciona Pods com esta label (todos os 3)
# --tail=20: √∫ltimas 20 linhas de cada Pod
# Voc√™ ver√° logs de requisi√ß√µes distribu√≠das entre os Pods

# 10. DELETAR O SERVICE (quando terminar)
sudo kubectl delete service nginx-service
# Deleta apenas o Service, os Pods continuam rodando
# Para deletar tudo:
# sudo kubectl delete deployment nginx-deployment
# sudo kubectl delete service nginx-service
```

**O que acontece:**
- Service cria um IP interno est√°vel (ClusterIP)
- NodePort exp√µe na porta 30080 de todos os Nodes
- Requisi√ß√µes em 30080 ‚Üí Service ‚Üí balanceamento entre os 3 Pods
- Se um Pod morrer, Service automaticamente remove do balanceamento
- Quando Pod novo fica pronto, Service adiciona de volta

**Problema deste n√≠vel:**
- NodePort usa portas altas (30000-32767), n√£o √© elegante
- Precisa lembrar/configurar porta espec√≠fica para cada aplica√ß√£o
- N√£o h√° roteamento por dom√≠nio (exemplo.com ‚Üí Service A, api.exemplo.com ‚Üí Service B)
- Para m√∫ltiplas aplica√ß√µes, precisa m√∫ltiplas portas NodePort

**Pr√≥ximo passo:** N√≠vel 4 resolver√° isso com **Ingress** (roteamento HTTP por dom√≠nio/path, porta 80/443 padr√£o).

Teste tudo. Principalmente acesse via navegador ou curl o `http://localhost:30080`. 

___

## N√≠vel 4: Ingress

**Problema do N√≠vel 3 resolvido:**
- NodePort usa portas altas (30000-32767), pouco conveniente
- Cada Service precisa de uma porta diferente
- Sem roteamento inteligente por dom√≠nio ou caminho (path)
- N√£o gerencia SSL/TLS de forma centralizada

**Solu√ß√£o do Ingress:**
- Exp√µe m√∫ltiplos Services na porta 80 (HTTP) e 443 (HTTPS)
- Roteamento por dom√≠nio: `app1.exemplo.com` ‚Üí Service A, `app2.exemplo.com` ‚Üí Service B
- Roteamento por path: `/api` ‚Üí Service A, `/web` ‚Üí Service B
- Gerenciamento centralizado de SSL/TLS
- Um √∫nico ponto de entrada para todo o cluster

<p align="center">
  <img src="/images/k8s/ingress.png" />
</p>

**Estrutura:**
```bash
projeto-k8s/
‚îú‚îÄ‚îÄ pod.yaml (n√≠vel 1 - refer√™ncia)
‚îú‚îÄ‚îÄ deployment.yaml (n√≠vel 2 - mant√©m rodando)
‚îú‚îÄ‚îÄ service.yaml (n√≠vel 3 - precisa ajustar!)
‚îî‚îÄ‚îÄ ingress.yaml (n√≠vel 4 - novo)
```

**IMPORTANTE:** O k3s j√° vem com **Traefik** (Ingress Controller) instalado por padr√£o. N√£o precisa instalar nada extra.

**Primeiro: Ajustar o Service para ClusterIP**

O Ingress funciona com Services tipo ClusterIP (n√£o NodePort). Vamos ajustar:

**Arquivo: service.yaml (ajustado)**
```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
  labels:
    app: nginx

spec:
  # type: ClusterIP (padr√£o)
  # Removemos NodePort porque agora o acesso ser√° via Ingress
  # ClusterIP = apenas acess√≠vel internamente no cluster
  # O Ingress (Traefik) acessa este ClusterIP e roteia tr√°fego externo
  type: ClusterIP
  
  selector:
    app: nginx
  
  ports:
    - protocol: TCP
      port: 80          # Porta do Service (interna)
      targetPort: 80    # Porta do container do Pod
      # nodePort: removido (n√£o √© mais necess√°rio)
```

**Arquivo: ingress.yaml (novo)**
```yaml
# apiVersion: networking.k8s.io/v1
# API espec√≠fica para recursos de rede (Ingress, NetworkPolicy)
# networking.k8s.io/v1 = vers√£o est√°vel do Ingress
apiVersion: networking.k8s.io/v1

# kind: Ingress
# Recurso que gerencia acesso HTTP/HTTPS externo aos Services
kind: Ingress

# metadata: Informa√ß√µes do Ingress
metadata:
  # Nome do Ingress
  name: nginx-ingress
  
  # annotations: Configura√ß√µes espec√≠ficas do Ingress Controller
  # Cada controller (Traefik, Nginx, HAProxy) tem suas pr√≥prias annotations
  # Opcional, mas muito usado para configura√ß√µes avan√ßadas
  annotations:
    # Exemplo de annotation para Traefik (Ingress Controller do k3s)
    # traefik.ingress.kubernetes.io/router.entrypoints: web
    # Por enquanto, deixaremos sem annotations (configura√ß√£o b√°sica)

# spec: Especifica√ß√£o do Ingress
spec:
  # ingressClassName: Qual Ingress Controller usar
  # k3s usa Traefik por padr√£o, a classe √© "traefik"
  # Se omitido, usa o controller padr√£o do cluster
  ingressClassName: traefik
  
  # rules: Regras de roteamento
  # Lista de regras que definem como rotear tr√°fego HTTP
  rules:
    # Cada regra pode ter:
    #   - host: dom√≠nio (exemplo.com)
    #   - http: configura√ß√µes de paths
    
    # Regra 1: Roteamento por dom√≠nio
    - host: nginx.local
      # host: dom√≠nio que receber√° as requisi√ß√µes
      # Para testar localmente, usaremos "nginx.local"
      # Em produ√ß√£o, seria seu dom√≠nio real (exemplo.com)
      
      http:
        # paths: Lista de caminhos (URLs) e para onde rotear
        paths:
          - path: /
            # path: caminho da URL
            # / = raiz (todas as URLs come√ßando com /)
            # Exemplos: /api, /admin, /app
            
            pathType: Prefix
            # pathType: Como interpretar o path
            # Tipos:
            #   Prefix: qualquer URL que COMECE com o path (/api, /api/users)
            #   Exact: apenas URL EXATA (/api, mas n√£o /api/users)
            #   ImplementationSpecific: depende do Ingress Controller
            
            backend:
              # backend: Para onde enviar o tr√°fego
              # Define qual Service receber√° as requisi√ß√µes
              
              service:
                name: nginx-service
                # name: nome do Service de destino
                # Deve existir no mesmo namespace
                
                port:
                  number: 80
                  # number: porta do Service (port do service.yaml)
                  # O Ingress envia tr√°fego para esta porta do Service
  
  # Regra 2 (opcional): Roteamento sem host espec√≠fico
  # Se omitir "host:", responde para QUALQUER dom√≠nio
  # √ötil para testes, mas n√£o recomendado em produ√ß√£o
  # Descomente se quiser testar via IP direto:

  # IMPORTANTE: Descomente a regra abaixo APENAS para testes locais
  # Em produ√ß√£o, sempre especifique o host para evitar conflitos
  # - http:
  #     paths:
  #       - path: /
  #         pathType: Prefix
  #         backend:
  #           service:
  #             name: nginx-service
  #             port:
  #               number: 80
```

**Comandos Detalhados:**

```bash
# 1. VERIFICAR SE TRAEFIK (INGRESS CONTROLLER) EST√Å RODANDO
sudo kubectl get pods -n kube-system | grep traefik
# Deve mostrar pods do Traefik rodando
# k3s instala Traefik automaticamente no namespace kube-system
# Se n√£o aparecer nada, o Traefik pode estar desabilitado (raro)

# 2. ATUALIZAR O SERVICE PARA ClusterIP
sudo kubectl apply -f service.yaml
# Atualiza o Service existente, mudando de NodePort para ClusterIP
# Os Pods continuam rodando normalmente

# 3. VERIFICAR O SERVICE ATUALIZADO
sudo kubectl get service nginx-service
# TYPE agora deve ser "ClusterIP" (n√£o mais NodePort)
# N√£o haver√° mais a porta 30080 exposta

# 4. CRIAR O INGRESS
sudo kubectl apply -f ingress.yaml
# Cria o recurso Ingress
# Traefik detecta automaticamente e configura o roteamento

# 5. VERIFICAR O INGRESS CRIADO
sudo kubectl get ingress
# Tamb√©m pode usar: sudo kubectl get ing
# Colunas:
#   NAME: nome do ingress
#   CLASS: Ingress Controller usado (traefik)
#   HOSTS: dom√≠nios configurados
#   ADDRESS: IP do Ingress Controller
#   PORTS: portas expostas (80, 443)
#   AGE: tempo desde cria√ß√£o
# Exemplo de sa√≠da:
# NAME            CLASS     HOSTS         ADDRESS         PORTS   AGE
# nginx-ingress   traefik   nginx.local   192.168.1.100   80      10s

# 6. VER DETALHES DO INGRESS
sudo kubectl describe ingress nginx-ingress
# Mostra:
#   - Regras de roteamento configuradas
#   - Backend (Service) de destino
#   - Eventos (cria√ß√£o, updates)
# Procure por "Rules:" e "Backend:" para ver a configura√ß√£o

# 7. CONFIGURAR DNS LOCAL (para testar com nginx.local)
# Op√ß√£o A: Editar /etc/hosts no servidor SSH
sudo nano /etc/hosts
# Adicione esta linha (substitua pelo IP do servidor):
# 127.0.0.1 nginx.local
# Salve: Ctrl+O, Enter, Ctrl+X

# Op√ß√£o B: Se estiver acessando de outra m√°quina
# No computador local, adicione no /etc/hosts (Linux/Mac) ou C:\Windows\System32\drivers\etc\hosts (Windows):
# IP_DO_SERVIDOR nginx.local

# 8. DESCOBRIR A PORTA DO TRAEFIK (k3s exp√µe na porta 80 do host)
# k3s configura Traefik para usar a porta 80 do servidor por padr√£o
# Verifique se est√° escutando:
sudo netstat -tulpn | grep :80
# Deve mostrar Traefik escutando na porta 80

# 9. TESTAR O INGRESS
# Op√ß√£o A: Pelo servidor SSH
curl -H "Host: nginx.local" http://localhost
# -H "Host: nginx.local": envia header Host (simula acesso via dom√≠nio)
# Deve retornar o HTML do nginx

# Op√ß√£o B: Se configurou /etc/hosts
curl http://nginx.local
# Deve retornar o HTML do nginx

# Op√ß√£o C: Via navegador (se tiver acesso ao IP do servidor)
# Ap√≥s configurar /etc/hosts no computador local:
# http://nginx.local

# 10. VERIFICAR LOGS DO TRAEFIK (Ingress Controller)
sudo kubectl logs -n kube-system -l app.kubernetes.io/name=traefik --tail=50
# -n kube-system: namespace onde Traefik est√° instalado
# -l app.kubernetes.io/name=traefik: filtra pods do Traefik
# --tail=50: √∫ltimas 50 linhas
# Deve mostrar requisi√ß√µes chegando via Ingress

# 11. TESTAR BALANCEAMENTO via Ingress
for i in {1..10}; do
  curl -H "Host: nginx.local" http://localhost
  echo "Requisi√ß√£o $i"
done
# Todas devem funcionar - Ingress ‚Üí Service ‚Üí 3 Pods balanceados

# 12. LISTAR TODOS OS RECURSOS CRIADOS
sudo kubectl get all
# Mostra: Pods, Services, Deployments
sudo kubectl get ingress
# Mostra: Ingress

# 13. DELETAR RECURSOS (quando terminar)
sudo kubectl delete ingress nginx-ingress    # Deleta Ingress
sudo kubectl delete service nginx-service    # Deleta Service
sudo kubectl delete deployment nginx-deployment  # Deleta Deployment (e Pods)

# Ou deletar tudo de uma vez com os arquivos:
# sudo kubectl delete -f ingress.yaml
# sudo kubectl delete -f service.yaml
# sudo kubectl delete -f deployment.yaml
```

**O que acontece:**
- Traefik (Ingress Controller) escuta na porta 80 do servidor
- Requisi√ß√£o chega: `http://nginx.local` ‚Üí Traefik
- Traefik l√™ as regras do Ingress: `nginx.local` ‚Üí Service `nginx-service`
- Service balanceia entre os 3 Pods
- Resposta volta: Pod ‚Üí Service ‚Üí Traefik ‚Üí Usu√°rio

**Fluxo completo:**
```bash
Navegador (nginx.local:80)
    ‚Üì
Traefik (Ingress Controller)
    ‚Üì
Ingress (regras de roteamento)
    ‚Üì
Service (nginx-service:80)
    ‚Üì
Pods (3 r√©plicas do nginx)
```

**Problema deste n√≠vel:**
- Configura√ß√£o manual de DNS (/etc/hosts) n√£o √© escal√°vel
- Sem SSL/TLS (apenas HTTP, n√£o HTTPS)
- Dados em disco n√£o persistem (se Pod reiniciar, perde dados)
- Sem gerenciamento de configura√ß√µes (tudo hardcoded)

**Pr√≥ximos passos poss√≠veis:**
- **N√≠vel 5:** ConfigMap e Secret (gerenciar configura√ß√µes e senhas)
- **N√≠vel 6:** PersistentVolume (armazenamento persistente)
- **N√≠vel 7:** Cert-Manager + Let's Encrypt (SSL/TLS autom√°tico)

Teste tudo, principalmente o acesso via `curl -H "Host: nginx.local" http://localhost`.

___

## N√≠vel 5: ConfigMap e Secret

**Problema do N√≠vel 4 resolvido:**
- Configura√ß√µes hardcoded nos arquivos YAML (imagem, portas, etc)
- Senhas e dados sens√≠veis direto no c√≥digo
- Mudar uma vari√°vel = recriar todo o Deployment
- Mesmo Deployment n√£o serve para dev/staging/produ√ß√£o
- Sem separa√ß√£o entre c√≥digo e configura√ß√£o

**Solu√ß√£o do ConfigMap e Secret:**
- **ConfigMap**: Armazena configura√ß√µes n√£o-sens√≠veis (URLs, features, textos)
- **Secret**: Armazena dados sens√≠veis (senhas, tokens, certificados) em Base64
- Injetar configura√ß√µes como vari√°veis de ambiente ou arquivos nos Pods
- Mudar configura√ß√£o sem recriar imagem Docker
- Reutilizar mesmo Deployment com configs diferentes

**Estrutura:**
```bash
projeto-k8s/
‚îú‚îÄ‚îÄ pod.yaml (n√≠vel 1 - refer√™ncia)
‚îú‚îÄ‚îÄ deployment.yaml (n√≠vel 2 - mant√©m)
‚îú‚îÄ‚îÄ service.yaml (n√≠vel 3 - mant√©m)
‚îú‚îÄ‚îÄ ingress.yaml (n√≠vel 4 - mant√©m)
‚îú‚îÄ‚îÄ configmap.yaml (n√≠vel 5 - novo)
‚îú‚îÄ‚îÄ secret.yaml (n√≠vel 5 - novo)
‚îî‚îÄ‚îÄ deployment-com-config.yaml (n√≠vel 5 - novo, vers√£o melhorada)
```

**Arquivo: configmap.yaml**
```yaml
# apiVersion: v1 (API core)
# ConfigMap √© recurso b√°sico do Kubernetes
apiVersion: v1

# kind: ConfigMap
# Armazena dados de configura√ß√£o n√£o-sens√≠veis em pares chave-valor
kind: ConfigMap

# metadata: Informa√ß√µes do ConfigMap
metadata:
  # Nome do ConfigMap
  # Pods referenciam este nome para consumir as configura√ß√µes
  name: nginx-config
  
  labels:
    app: nginx

# data: Dados de configura√ß√£o (chave-valor)
# Tudo aqui √© texto plano (N√ÉO use para senhas!)
data:
  # Formato: chave: "valor"
  # Valores podem ser strings simples ou arquivos inteiros
  
  # Exemplo 1: Vari√°veis simples (chave-valor)
  # Ser√£o injetadas como vari√°veis de ambiente no Pod
  APP_NAME: "Meu Nginx"
  APP_VERSION: "1.0.0"
  LOG_LEVEL: "info"
  
  # Exemplo 2: Arquivo de configura√ß√£o completo
  # Ser√° montado como arquivo dentro do container
  # Arquivo: nginx.conf (configura√ß√£o customizada do nginx)
  nginx.conf: |
    # O pipe "|" indica texto multilinha
    # Tudo indentado abaixo ser√° o conte√∫do do arquivo
    server {
        listen 80;
        server_name localhost;
        
        location / {
            root /usr/share/nginx/html;
            index index.html;
        }
        
        # Adiciona header customizado (para testar que config foi aplicada)
        add_header X-Config-From "ConfigMap";
        add_header X-App-Name "Meu Nginx";
    }
  
  # Exemplo 3: Arquivo HTML customizado
  # Ser√° montado como /usr/share/nginx/html/index.html
  index.html: |
    <!DOCTYPE html>
    <html>
    <head>
        <title>Nginx com ConfigMap</title>
        <style>
            body { 
                font-family: Arial; 
                text-align: center; 
                padding: 50px;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
            }
            .container {
                background: rgba(255,255,255,0.1);
                padding: 30px;
                border-radius: 10px;
            }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>üöÄ Nginx com ConfigMap!</h1>
            <p>Esta p√°gina foi injetada via ConfigMap do Kubernetes</p>
            <p>Vers√£o: 1.0.0</p>
        </div>
    </body>
    </html>
```

**Arquivo: secret.yaml**
```yaml
# apiVersion: v1 (API core)
apiVersion: v1

# kind: Secret
# Armazena dados sens√≠veis em Base64
# N√ÉO √© criptografia real! Base64 √© apenas encoding
# Para seguran√ßa real, use solu√ß√µes como Sealed Secrets ou Vault
kind: Secret

# metadata: Informa√ß√µes do Secret
metadata:
  name: nginx-secret
  labels:
    app: nginx

# type: Tipo do Secret
# Tipos dispon√≠veis:
#   Opaque: gen√©rico (padr√£o, usado aqui)
#   kubernetes.io/dockerconfigjson: credenciais de registry Docker
#   kubernetes.io/tls: certificados TLS
#   kubernetes.io/basic-auth: usu√°rio/senha
#   kubernetes.io/ssh-auth: chaves SSH
type: Opaque

# data: Dados sens√≠veis em Base64
# Valores DEVEM estar em Base64
# Para converter: echo -n "valor" | base64
data:
  # Exemplo: senha de banco de dados
  # Valor original: "minha-senha-super-secreta"
  # Base64: bWluaGEtc2VuaGEtc3VwZXItc2VjcmV0YQ==
  DB_PASSWORD: bWluaGEtc2VuaGEtc3VwZXItc2VjcmV0YQ==
  
  # Exemplo: API token
  # Valor original: "token-12345-abcde"
  # Base64: dG9rZW4tMTIzNDUtYWJjZGU=
  API_TOKEN: dG9rZW4tMTIzNDUtYWJjZGU=

# stringData: Alternativa ao "data" (opcional)
# Valores em texto plano, K8s converte automaticamente para Base64
# Mais conveniente, mas menos seguro (fica vis√≠vel no arquivo)
stringData:
  # Exemplo: usu√°rio de banco
  DB_USERNAME: "admin"
  
  # Exemplo: chave de API
  SECRET_KEY: "chave-secreta-aqui"
```

**Arquivo: deployment-com-config.yaml**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment-config
  labels:
    app: nginx-config

spec:
  replicas: 2
  
  selector:
    matchLabels:
      app: nginx-config
  
  template:
    metadata:
      labels:
        app: nginx-config
    
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
        
        # env: Vari√°veis de ambiente
        # Injetando valores do ConfigMap e Secret
        env:
          # Vari√°vel do ConfigMap (m√©todo 1: refer√™ncia direta)
          - name: APP_NAME
            # name: nome da vari√°vel de ambiente no container
            valueFrom:
              # valueFrom: buscar valor de outro recurso
              configMapKeyRef:
                # configMapKeyRef: refer√™ncia a uma chave do ConfigMap
                name: nginx-config       # Nome do ConfigMap
                key: APP_NAME            # Chave dentro do ConfigMap
          
          - name: APP_VERSION
            valueFrom:
              configMapKeyRef:
                name: nginx-config
                key: APP_VERSION
          
          # Vari√°vel do Secret (m√©todo 1: refer√™ncia direta)
          - name: DB_PASSWORD
            valueFrom:
              secretKeyRef:
                # secretKeyRef: refer√™ncia a uma chave do Secret
                name: nginx-secret       # Nome do Secret
                key: DB_PASSWORD         # Chave dentro do Secret
                # Valor ser√° decodificado de Base64 automaticamente
          
          - name: DB_USERNAME
            valueFrom:
              secretKeyRef:
                name: nginx-secret
                key: DB_USERNAME
        
        # envFrom: Importar TODAS as chaves como vari√°veis (m√©todo 2)
        # Mais conveniente quando tem muitas vari√°veis
        envFrom:
          # Importa todas as chaves do ConfigMap como vari√°veis
          - configMapRef:
              name: nginx-config
          # Importa todas as chaves do Secret como vari√°veis
          - secretRef:
              name: nginx-secret
        
        # volumeMounts: Montar ConfigMap/Secret como arquivos
        # √ötil para arquivos de configura√ß√£o (nginx.conf, etc)
        volumeMounts:
          # Mount 1: Arquivo nginx.conf do ConfigMap
          - name: config-volume
            # name: refer√™ncia ao volume definido em "volumes" abaixo
            mountPath: /etc/nginx/conf.d/default.conf
            # mountPath: onde o arquivo ser√° montado no container
            subPath: nginx.conf
            # subPath: qual chave do ConfigMap usar como arquivo
            # Sem subPath, montaria todas as chaves como arquivos separados
          
          # Mount 2: Arquivo index.html do ConfigMap
          - name: html-volume
            mountPath: /usr/share/nginx/html/index.html
            subPath: index.html
        
        resources:
          requests:
            memory: "64Mi"
            cpu: "250m"
          limits:
            memory: "128Mi"
            cpu: "500m"
      
      # volumes: Definir volumes baseados em ConfigMap/Secret
      # Vincula ConfigMaps/Secrets para serem montados nos containers
      volumes:
        # Volume 1: nginx.conf
        - name: config-volume
          # name: nome do volume (usado em volumeMounts)
          configMap:
            # configMap: este volume vem de um ConfigMap
            name: nginx-config
            # name: qual ConfigMap usar
            items:
              # items: quais chaves do ConfigMap incluir (opcional)
              - key: nginx.conf
                # key: chave do ConfigMap
                path: nginx.conf
                # path: nome do arquivo no volume
        
        # Volume 2: index.html
        - name: html-volume
          configMap:
            name: nginx-config
            items:
              - key: index.html
                path: index.html
```

**Comandos Detalhados:**

```bash
# 1. CRIAR O CONFIGMAP
sudo kubectl apply -f configmap.yaml
# ConfigMap criado com vari√°veis e arquivos de configura√ß√£o

# 2. VERIFICAR O CONFIGMAP
sudo kubectl get configmap
# Tamb√©m pode usar: sudo kubectl get cm
# Lista todos os ConfigMaps do namespace

sudo kubectl describe configmap nginx-config
# Mostra todas as chaves e valores (parcialmente, se muito grande)

# Ver conte√∫do completo do ConfigMap:
sudo kubectl get configmap nginx-config -o yaml
# -o yaml: sa√≠da em formato YAML (mostra tudo)

# 3. CRIAR O SECRET
sudo kubectl apply -f secret.yaml
# Secret criado com dados sens√≠veis em Base64

# 4. VERIFICAR O SECRET
sudo kubectl get secret
# Lista todos os Secrets

sudo kubectl describe secret nginx-secret
# Mostra chaves, MAS N√ÉO mostra os valores (seguran√ßa)

# Ver conte√∫do do Secret (Base64):
sudo kubectl get secret nginx-secret -o yaml
# Mostra valores em Base64

# Decodificar um valor do Secret:
sudo kubectl get secret nginx-secret -o jsonpath='{.data.DB_PASSWORD}' | base64 -d
# Deve mostrar: minha-senha-super-secreta
# -o jsonpath: extrai campo espec√≠fico
# base64 -d: decodifica de Base64

# 5. CRIAR O DEPLOYMENT COM CONFIGMAP E SECRET
sudo kubectl apply -f deployment-com-config.yaml
# Deployment criado, Pods receber√£o as configura√ß√µes

# 6. VERIFICAR PODS
sudo kubectl get pods -l app=nginx-config
# -l app=nginx-config: filtra pods com esta label
# Deve mostrar 2 Pods rodando

# 7. TESTAR VARI√ÅVEIS DE AMBIENTE INJETADAS
# Acessar um Pod e ver as vari√°veis
sudo kubectl get pods -l app=nginx-config  # Copie nome de um Pod
sudo kubectl exec -it nginx-deployment-config-xxxxxxxxx-xxxxx -- env | grep -E "APP_|DB_|SECRET_"
# exec -it: executa comando no container de forma interativa
# env: lista vari√°veis de ambiente
# grep: filtra apenas vari√°veis que come√ßam com APP_, DB_, SECRET_
# Deve mostrar:
#   APP_NAME=Meu Nginx
#   APP_VERSION=1.0.0
#   DB_PASSWORD=minha-senha-super-secreta
#   DB_USERNAME=admin
#   etc.

# 8. TESTAR ARQUIVOS MONTADOS DO CONFIGMAP
# Ver se nginx.conf foi montado corretamente:
sudo kubectl exec nginx-deployment-config-xxxxxxxxx-xxxxx -- cat /etc/nginx/conf.d/default.conf
# Deve mostrar o conte√∫do do nginx.conf que definimos no ConfigMap

# Ver se index.html foi montado:
sudo kubectl exec nginx-deployment-config-xxxxxxxxx-xxxxx -- cat /usr/share/nginx/html/index.html
# Deve mostrar o HTML customizado

# 9. CRIAR SERVICE PARA O NOVO DEPLOYMENT
# Criar arquivo: service-config.yaml (ou ajustar o service.yaml existente)
cat <<EOF | sudo kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  name: nginx-service-config
spec:
  type: ClusterIP
  selector:
    app: nginx-config
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
EOF
# Usa "heredoc" para criar Service inline (sem arquivo separado)

# 10. ATUALIZAR INGRESS PARA APONTAR PARA O NOVO SERVICE
# Editar ingress.yaml, mudar:
#   service.name: nginx-service-config
# Ou criar inline:
cat <<EOF | sudo kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nginx-ingress-config
spec:
  ingressClassName: traefik
  rules:
    - host: nginx-config.local
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: nginx-service-config
                port:
                  number: 80
EOF

# 11. ATUALIZAR /etc/hosts
sudo nano /etc/hosts
# Adicione:
# 127.0.0.1 nginx-config.local

# 12. TESTAR VIA INGRESS
curl http://nginx-config.local
# Deve retornar o HTML customizado do ConfigMap!

# Verificar headers customizados (do nginx.conf):
curl -I http://nginx-config.local
# -I: mostra apenas headers
# Deve mostrar:
#   X-Config-From: ConfigMap
#   X-App-Name: Meu Nginx

# 13. ATUALIZAR CONFIGMAP SEM RECRIAR PODS
# Editar o ConfigMap:
sudo kubectl edit configmap nginx-config
# Muda no editor (vim/nano): APP_VERSION: "1.0.0" ‚Üí "2.0.0"
# Salve e feche

# Ver a vari√°vel no Pod (pode demorar alguns minutos para atualizar):
sudo kubectl exec nginx-deployment-config-xxxxxxxxx-xxxxx -- env | grep APP_VERSION
# ConfigMaps montados como volumes atualizam automaticamente (1-2 min)
# Vari√°veis de ambiente N√ÉO atualizam (precisa recriar Pod)

# For√ßar recrea√ß√£o dos Pods para pegar novas vari√°veis:
sudo kubectl rollout restart deployment nginx-deployment-config
# rollout restart: recria Pods gradualmente (zero downtime)

# 14. CRIAR CONFIGMAP/SECRET VIA LINHA DE COMANDO (alternativa)
# Criar ConfigMap de arquivo:
echo "Teste" > teste.txt
sudo kubectl create configmap meu-config --from-file=teste.txt
# --from-file: cria chave "teste.txt" com conte√∫do do arquivo

# Criar ConfigMap de literal:
sudo kubectl create configmap meu-config2 --from-literal=chave=valor
# --from-literal: cria chave-valor diretamente

# Criar Secret de literal:
sudo kubectl create secret generic meu-secret --from-literal=senha=123456
# generic: tipo Opaque

# 15. VER LOGS DOS PODS
sudo kubectl logs -l app=nginx-config --tail=20
# Logs dos Pods do novo Deployment

# 16. DELETAR RECURSOS (quando terminar)
sudo kubectl delete deployment nginx-deployment-config
sudo kubectl delete service nginx-service-config
sudo kubectl delete ingress nginx-ingress-config
sudo kubectl delete configmap nginx-config
sudo kubectl delete secret nginx-secret
```

**O que acontece:**

**ConfigMap:**
- Armazena configura√ß√µes n√£o-sens√≠veis (texto plano)
- Pode ser injetado como vari√°veis de ambiente: `env.valueFrom.configMapKeyRef`
- Pode ser montado como arquivo: `volumes.configMap` + `volumeMounts`
- Atualiza arquivos montados automaticamente (1-2 min)
- Vari√°veis de ambiente N√ÉO atualizam (precisa recriar Pod)

**Secret:**
- Armazena dados sens√≠veis em Base64 (n√£o √© criptografia!)
- Mesmo uso que ConfigMap: vari√°veis ou arquivos
- K8s decodifica Base64 automaticamente ao injetar
- `kubectl describe secret` n√£o mostra valores (seguran√ßa b√°sica)

**Fluxo:**
```bash
ConfigMap/Secret (armazenamento)
    ‚Üì
Deployment (referencia)
    ‚Üì
Pod (recebe via env ou volume)
    ‚Üì
Container (usa as configura√ß√µes)
```

**Problema deste n√≠vel:**
- Secrets em Base64 n√£o s√£o criptografados (qualquer um com acesso ao cluster l√™)
- Dados em disco ainda n√£o persistem (Pods reiniciam = dados perdidos)
- ConfigMaps grandes poluem o arquivo YAML
- Sem versionamento autom√°tico de configura√ß√µes
- Precisa gerenciar manualmente ambientes (dev/prod)

Teste tudo, principalmente o `curl http://nginx-config.local` para ver o HTML customizado.

Isso foi algo muito b√°sico com kubernetes, mas conforme voc√™ vai aprendendo, novas funcionalidades ir√£o surgir. Espero que tenha gostado.

E o melhor: **tudo open-source e de gra√ßa**.

Curtiu? Compartilha a√≠ e me marca! Tem d√∫vidas? Comenta que eu respondo.

At√© a pr√≥xima!